{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:15:21.935110Z",
     "start_time": "2024-05-18T12:15:20.823503Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib as mpl\n",
    "import scipy.stats as st\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from tqdm import tqdm\n",
    "from plotly import tools\n",
    "from pandas import json_normalize\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create a list of colors \n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "np.set_printoptions(formatter={'float': '{: 0.0f}'.format})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read csv and flatten json fields:   \n",
    "https://www.kaggle.com/julian3833/1-quick-start-read-csv-and-flatten-json-fields\n",
    "\n",
    "- Take string as an input and create a json object with the specified string as object name   \n",
    "https://towardsdatascience.com/why-and-how-to-use-pandas-with-large-data-9594dda2ea4c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:15:22.566602Z",
     "start_time": "2024-05-18T12:15:22.559241Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Extract features from 'device', 'geoNetwork', 'totals', 'trafficSourceâ€™. \n",
    "json_columns = ['device', 'geoNetwork','totals', 'trafficSource']\n",
    "\n",
    "def load_dataframe(csv_path):\n",
    "    path = csv_path\n",
    "    df = pd.read_csv(path, converters={column: json.loads for column in json_columns}, \n",
    "                     dtype={'fullVisitorId': 'str'})\n",
    "   \n",
    "    for column in json_columns:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        column_as_df.columns = [f\"{column}_{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:17:27.003424Z",
     "start_time": "2024-05-18T12:15:22.620760Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train \u001b[38;5;241m=\u001b[39m load_dataframe(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m test \u001b[38;5;241m=\u001b[39m load_dataframe(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m, in \u001b[0;36mload_dataframe\u001b[1;34m(csv_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_dataframe\u001b[39m(csv_path):\n\u001b[0;32m      5\u001b[0m     path \u001b[38;5;241m=\u001b[39m csv_path\n\u001b[1;32m----> 6\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(path, converters\u001b[38;5;241m=\u001b[39m{column: json\u001b[38;5;241m.\u001b[39mloads \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m json_columns}, \n\u001b[0;32m      7\u001b[0m                      dtype\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfullVisitorId\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m json_columns:\n\u001b[0;32m     10\u001b[0m         column_as_df \u001b[38;5;241m=\u001b[39m json_normalize(df[column])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
     ]
    }
   ],
   "source": [
    "train = load_dataframe('train.csv')\n",
    "test = load_dataframe('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:04.446015Z",
     "start_time": "2024-05-18T12:17:27.006937Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Store the dataframes as csv files\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_df.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m test\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_df.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# Store the dataframes as csv files\n",
    "train.to_csv('train_df.csv')\n",
    "test.to_csv('test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:25.753935Z",
     "start_time": "2024-05-18T12:18:04.446015Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read csv files\n",
    "train = pd.read_csv('train_df.csv', dtype={'fullVisitorId': 'str'}, index_col=0)\n",
    "\n",
    "test = pd.read_csv('test_df.csv', dtype={'fullVisitorId': 'str'}, index_col=0)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:25.848677Z",
     "start_time": "2024-05-18T12:18:25.753935Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:26.960724Z",
     "start_time": "2024-05-18T12:18:25.852184Z"
    }
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:26.978433Z",
     "start_time": "2024-05-18T12:18:26.961984Z"
    }
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:27.868384Z",
     "start_time": "2024-05-18T12:18:26.979949Z"
    }
   },
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2.1 Remove Constant Features\n",
    "\n",
    "Features that have only one unique value are often referred to as constant features or constant columns.   \n",
    "\n",
    "These features do not provide any variability in the data, and as a result, they typically do not contribute    \n",
    "useful information to the model. We might as well drop these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:27.886859Z",
     "start_time": "2024-05-18T12:18:27.870393Z"
    }
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:27.916004Z",
     "start_time": "2024-05-18T12:18:27.888849Z"
    }
   },
   "outputs": [],
   "source": [
    "# Keep 'totals_bounces' column\n",
    "train['totals_bounces'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:27.942459Z",
     "start_time": "2024-05-18T12:18:27.918012Z"
    }
   },
   "outputs": [],
   "source": [
    "train['totals_bounces'].fillna(0, inplace=True)\n",
    "train['totals_bounces'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:31.196369Z",
     "start_time": "2024-05-18T12:18:27.942459Z"
    }
   },
   "outputs": [],
   "source": [
    "# check unique values in train columns\n",
    "train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:34.540730Z",
     "start_time": "2024-05-18T12:18:31.196369Z"
    }
   },
   "outputs": [],
   "source": [
    "# Identify constant features\n",
    "constant_features = train.columns[train.nunique() == 1]\n",
    "\n",
    "# Remove constant features\n",
    "train.drop(columns=constant_features, inplace=True)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:34.557068Z",
     "start_time": "2024-05-18T12:18:34.540730Z"
    }
   },
   "outputs": [],
   "source": [
    "# Keep 'totals_bounces' column\n",
    "test['totals_bounces'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:34.593900Z",
     "start_time": "2024-05-18T12:18:34.561098Z"
    }
   },
   "outputs": [],
   "source": [
    "test['totals_bounces'].fillna(0, inplace=True)\n",
    "test['totals_bounces'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:37.441014Z",
     "start_time": "2024-05-18T12:18:34.593900Z"
    }
   },
   "outputs": [],
   "source": [
    "# check unique values in test columns\n",
    "test.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:40.360758Z",
     "start_time": "2024-05-18T12:18:37.450259Z"
    }
   },
   "outputs": [],
   "source": [
    "# Identify constant features\n",
    "constant_features = test.columns[test.nunique() == 1]\n",
    "\n",
    "# Remove constant features\n",
    "test.drop(columns=constant_features, inplace=True)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Find Percentage of missing values in the columns\n",
    "\n",
    "- credits:   \n",
    "https://stackoverflow.com/questions/51070985/find-out-the-percentage-of-missing-values-in-each-column-in-the-given-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:40.904308Z",
     "start_time": "2024-05-18T12:18:40.364274Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_df - Check the percentage of missing values in each column\n",
    "percent_missing_train = train.isnull().sum() * 100 / len(train)\n",
    "\n",
    "missing_value_train = pd.DataFrame({'percent_missing': percent_missing_train})\n",
    "missing_value_train.sort_values(by='percent_missing', ascending=False, inplace=True)\n",
    "\n",
    "# Columns with percent_missing > 0\n",
    "missing_value_train_filtered = missing_value_train.loc[missing_value_train['percent_missing'] > 0]\n",
    "missing_value_train_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:41.405802Z",
     "start_time": "2024-05-18T12:18:40.904308Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_df - Check the percentage of missing values in each column\n",
    "percent_missing_test = test.isnull().sum() * 100 / len(test)\n",
    "\n",
    "missing_value_test = pd.DataFrame({#'column_name': test_df.columns,\n",
    "                                 'percent_missing': percent_missing_test})\n",
    "missing_value_test.sort_values(by='percent_missing', ascending=False, inplace=True)\n",
    "\n",
    "# Columns with percent_missing > 0\n",
    "missing_value_test_filtered = missing_value_test.loc[missing_value_test['percent_missing'] > 0]\n",
    "missing_value_test_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Columns to Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:41.415291Z",
     "start_time": "2024-05-18T12:18:41.406480Z"
    }
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:41.424674Z",
     "start_time": "2024-05-18T12:18:41.416424Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_to_drop = ['geoNetwork_continent', 'geoNetwork_subContinent', \n",
    "                'geoNetwork_metro', 'geoNetwork_city', 'geoNetwork_networkDomain', \n",
    "                'trafficSource_campaign', 'trafficSource_keyword',\n",
    "                'trafficSource_referralPath', 'trafficSource_adwordsClickInfo.page',\n",
    "                'trafficSource_adwordsClickInfo.slot', 'trafficSource_adwordsClickInfo.gclId',\n",
    "                'trafficSource_adContent', 'visitId', 'visitStartTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:41.747856Z",
     "start_time": "2024-05-18T12:18:41.425876Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = train.copy()\n",
    "\n",
    "df_train = df_train.drop(columns=cols_to_drop, axis=1)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:42.019264Z",
     "start_time": "2024-05-18T12:18:41.747856Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:42.142784Z",
     "start_time": "2024-05-18T12:18:42.019264Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:42.410010Z",
     "start_time": "2024-05-18T12:18:42.142784Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = test.copy()\n",
    "\n",
    "df_test = df_test.drop(columns=cols_to_drop, axis=1)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:42.696263Z",
     "start_time": "2024-05-18T12:18:42.410010Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:42.804536Z",
     "start_time": "2024-05-18T12:18:42.696263Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Impute Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:42.824076Z",
     "start_time": "2024-05-18T12:18:42.804536Z"
    }
   },
   "outputs": [],
   "source": [
    "# numerical columns fillna\n",
    "df_train['totals_pageviews'].fillna(0, inplace=True)\n",
    "df_train['totals_transactionRevenue'].fillna(0, inplace=True)\n",
    "\n",
    "df_test['totals_pageviews'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:42.835179Z",
     "start_time": "2024-05-18T12:18:42.824076Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:43.611744Z",
     "start_time": "2024-05-18T12:18:42.835179Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace 'nan', 'NaN', '(not set)' in both dataframes\n",
    "columns_to_process = ['device_browser', 'device_operatingSystem', 'trafficSource_source', \n",
    "                      'trafficSource_medium', 'trafficSource_adwordsClickInfo.adNetworkType']\n",
    "\n",
    "values_to_replace = ['nan', 'NaN', '(not set)', np.nan]\n",
    "replacement_value = 'others'\n",
    "\n",
    "for column in columns_to_process:\n",
    "    df_train[column].replace(values_to_replace, replacement_value, inplace=True)\n",
    "\n",
    "for column in columns_to_process:\n",
    "    df_test[column].replace(values_to_replace, replacement_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:43.660173Z",
     "start_time": "2024-05-18T12:18:43.611744Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['trafficSource_adwordsClickInfo.adNetworkType'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:43.668946Z",
     "start_time": "2024-05-18T12:18:43.660173Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find the mismatched columns and the target variable\n",
    "train_columns = set(df_train.columns)\n",
    "test_columns = set(df_test.columns)\n",
    "mismatched_columns = train_columns.symmetric_difference(test_columns)\n",
    "\n",
    "print(\"Columns that don't match:\")\n",
    "print(mismatched_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 'channelGrouping' & 'device' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:46.521547Z",
     "start_time": "2024-05-18T12:18:43.668946Z"
    }
   },
   "outputs": [],
   "source": [
    "device_columns = ['channelGrouping', 'device_browser', 'device_operatingSystem', \n",
    "                  'device_isMobile', 'device_deviceCategory']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "for i, col in enumerate(device_columns, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    \n",
    "    ax = sns.countplot(y=df_train[col], order=df_train[col].value_counts()[:10].index, )\n",
    "    plt.title(f'Count of {col}')\n",
    "\n",
    "    total = len(df_train[col])\n",
    "\n",
    "    for c in ax.containers:\n",
    "        percentages = [f'{(v / total) * 100:.2f}%' for v in c.datavalues]\n",
    "        ax.bar_label(c, labels=percentages, fmt='%s', padding=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Explicitly close the figure to remove overlapping axes\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:46.533652Z",
     "start_time": "2024-05-18T12:18:46.521547Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the aggregation functions for each column\n",
    "aggregations = {'fullVisitorId': 'count',\n",
    "                'totals_pageviews': 'sum',\n",
    "                'totals_transactionRevenue': 'sum'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:46.649485Z",
     "start_time": "2024-05-18T12:18:46.533652Z"
    }
   },
   "outputs": [],
   "source": [
    "df_channels = df_train.groupby('channelGrouping').agg(aggregations\n",
    "                                ).sort_values(by='totals_transactionRevenue', ascending=False)\n",
    "\n",
    "df_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:47.401398Z",
     "start_time": "2024-05-18T12:18:46.649485Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "\n",
    "# Plot each column in a separate subplot\n",
    "for i, col in enumerate(df_channels.columns):\n",
    "    df_channels[col].sort_values().plot(kind='barh', ax=axes[i], \n",
    "                                        color=colors)\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel('Count')\n",
    "\n",
    "    total = df_channels[col].sum()\n",
    "\n",
    "    for c in axes[i].containers:\n",
    "        percentages = [f'{(v / total) * 100:.2f}%' for v in c.datavalues]\n",
    "        axes[i].bar_label(c, labels=percentages, fmt='%s', padding=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Observations:**\n",
    "\n",
    "- Organic Search brings about the highest number of users & pageviews, but\n",
    "- Referral brings in close to half of the revenues.\n",
    "- Direct ranks the 3rd both in number of users & pageviews, yet second only to   \n",
    "    Referral in terms of generating revenues as users know pretty much what they want.\n",
    "- Social Media is not as effective in generating revenues as in generating the traffics.\n",
    "- Paid Search has got what the advertisers have paid for: equal amount of traffics, pageviews   \n",
    "    & revenues\n",
    "- Affiliates are not that much effective compared with other channels above,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 'device_browser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:47.511551Z",
     "start_time": "2024-05-18T12:18:47.401398Z"
    }
   },
   "outputs": [],
   "source": [
    "df_browser = df_train.groupby('device_browser').agg(aggregations\n",
    "                ).sort_values(by='totals_transactionRevenue', ascending=False).head(10)\n",
    "\n",
    "df_browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:48.275378Z",
     "start_time": "2024-05-18T12:18:47.511551Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "\n",
    "# Plot each column in a separate subplot\n",
    "for i, col in enumerate(df_browser.columns):\n",
    "    df_browser[col].sort_values().plot(kind='barh', ax=axes[i], color=colors)\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel('Count')\n",
    "\n",
    "    total = df_browser[col].sum()\n",
    "\n",
    "    for c in axes[i].containers:\n",
    "        percentages = [f'{(v / total) * 100:.2f}%' for v in c.datavalues]\n",
    "        axes[i].bar_label(c, labels=percentages, fmt='%s', padding=1)\n",
    "\n",
    "plt.suptitle('Browsers')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Observations:**\n",
    "   \n",
    "- Not suprising, Chrome is the powerhouse in all 3 fields, especially in    \n",
    "    generating the revenues, close to 90 percent of the market share.\n",
    "- Surprisingly, both Safari & Firefox outperforms Internet Explorer & Edge    \n",
    "    in all 3 fields.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 'device_operatingSystem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:48.397142Z",
     "start_time": "2024-05-18T12:18:48.276976Z"
    }
   },
   "outputs": [],
   "source": [
    "df_os = df_train.groupby('device_operatingSystem').agg(aggregations\n",
    "                ).sort_values(by='totals_transactionRevenue', ascending=False).head(10)\n",
    "\n",
    "df_os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:49.075307Z",
     "start_time": "2024-05-18T12:18:48.397142Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "\n",
    "# Plot each column in a separate subplot\n",
    "for i, col in enumerate(df_os.columns):\n",
    "    df_os[col].sort_values().plot(kind='barh', ax=axes[i], color=colors)\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel('Count')\n",
    "\n",
    "    total = df_os[col].sum()\n",
    "\n",
    "    for c in axes[i].containers:\n",
    "        percentages = [f'{(v / total) * 100:.2f}%' for v in c.datavalues]\n",
    "        axes[i].bar_label(c, labels=percentages, fmt='%s', padding=1)\n",
    "\n",
    "plt.suptitle('Operating Systems')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 'device_isMobile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:49.140917Z",
     "start_time": "2024-05-18T12:18:49.075307Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mobile = df_train.groupby('device_isMobile').agg(aggregations\n",
    "                ).sort_values(by='totals_transactionRevenue', ascending=False)\n",
    "\n",
    "df_mobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:49.719415Z",
     "start_time": "2024-05-18T12:18:49.148578Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "\n",
    "# Flatten the 2D array of axes\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each column in a separate subplot\n",
    "for i, col in enumerate(df_mobile.columns):\n",
    "    df_mobile[col].sort_values().plot(kind='barh', ax=axes[i], color=colors)\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel('Count')\n",
    "\n",
    "    total = df_mobile[col].sum()\n",
    "\n",
    "    for c in axes[i].containers:\n",
    "        percentages = [f'{(v / total) * 100:.2f}%' for v in c.datavalues]\n",
    "        axes[i].bar_label(c, labels=percentages, fmt='%s', padding=1)\n",
    "\n",
    "plt.suptitle('Mobile vs Non-Mobile')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 'device.deviceCategory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:49.925928Z",
     "start_time": "2024-05-18T12:18:49.723341Z"
    }
   },
   "outputs": [],
   "source": [
    "df_category = df_train.groupby('device_deviceCategory').agg(aggregations\n",
    "                ).sort_values(by='totals_transactionRevenue', ascending=False).head(10)\n",
    "\n",
    "df_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:50.511500Z",
     "start_time": "2024-05-18T12:18:49.925928Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "\n",
    "# Plot each column in a separate subplot\n",
    "for i, col in enumerate(df_category.columns):\n",
    "    df_category[col].sort_values().plot(kind='barh', ax=axes[i], color=colors)\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel('Count')\n",
    "\n",
    "    total = df_category[col].sum()\n",
    "\n",
    "    for c in axes[i].containers:\n",
    "        percentages = [f'{(v / total) * 100:.2f}%' for v in c.datavalues]\n",
    "        axes[i].bar_label(c, labels=percentages, fmt='%s', padding=1)\n",
    "\n",
    "plt.suptitle('Device Category')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Observations:**\n",
    "\n",
    "desktop & non-mobile devices\n",
    "- still dominate in bring in traffics, pageviews & revenues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:51.613117Z",
     "start_time": "2024-05-18T12:18:50.511500Z"
    }
   },
   "outputs": [],
   "source": [
    "device_cols = [\"device_browser\", \"device_deviceCategory\", \"device_operatingSystem\"]\n",
    "\n",
    "colors = [\"#d6a5ff\", \"#fca6da\", \"#f4d39c\", \"#a9fcca\"]\n",
    "traces = []\n",
    "for i, col in enumerate(device_cols):\n",
    "    t = train[col].value_counts()\n",
    "    traces.append(go.Bar(marker=dict(color=colors[i]),orientation=\"h\", y = t.index[:15][::-1], x = t.values[:15][::-1]))\n",
    "\n",
    "fig = tools.make_subplots(rows=1, cols=3, subplot_titles=[\"Visits: Category\", \"Visits: Browser\",\"Visits: OS\"], print_grid=False)\n",
    "fig.append_trace(traces[1], 1, 1)\n",
    "fig.append_trace(traces[0], 1, 2)\n",
    "fig.append_trace(traces[2], 1, 3)\n",
    "\n",
    "fig['layout'].update(height=400, showlegend=False, title=\"Visits by Device Attributes\")\n",
    "iplot(fig)\n",
    "\n",
    "## convert transaction revenue to float\n",
    "train[\"totals_transactionRevenue\"] = train[\"totals_transactionRevenue\"].astype('float')\n",
    "\n",
    "device_cols = [\"device_browser\", \"device_deviceCategory\", \"device_operatingSystem\"]\n",
    "\n",
    "fig = tools.make_subplots(rows=1, cols=3, subplot_titles=[\"Mean Revenue: Category\", \"Mean Revenue: Browser\",\"Mean Revenue: OS\"], print_grid=False)\n",
    "\n",
    "colors = [\"red\", \"green\", \"purple\"]\n",
    "trs = []\n",
    "for i, col in enumerate(device_cols):\n",
    "    tmp = train.groupby(col).agg({\"totals_transactionRevenue\": \"mean\"}).reset_index().rename(columns={\"totals_transactionRevenue\" : \"Mean Revenue\"})\n",
    "    tmp = tmp.dropna().sort_values(\"Mean Revenue\", ascending = False)\n",
    "    tr = go.Bar(x = tmp[\"Mean Revenue\"][::-1], orientation=\"h\", marker=dict(opacity=0.5, color=colors[i]), y = tmp[col][::-1])\n",
    "    trs.append(tr)\n",
    "\n",
    "fig.append_trace(trs[1], 1, 1)\n",
    "fig.append_trace(trs[0], 1, 2)\n",
    "fig.append_trace(trs[2], 1, 3)\n",
    "fig['layout'].update(height=400, showlegend=False, title=\"Mean Revenue by Device Attributes\")\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  GeoNetwork Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:52.064791Z",
     "start_time": "2024-05-18T12:18:51.624836Z"
    }
   },
   "outputs": [],
   "source": [
    "geo_cols = ['geoNetwork_city', 'geoNetwork_continent','geoNetwork_country',\n",
    "            'geoNetwork_metro', 'geoNetwork_networkDomain', 'geoNetwork_region','geoNetwork_subContinent']\n",
    "geo_cols = ['geoNetwork_continent','geoNetwork_subContinent']\n",
    "\n",
    "colors = [\"#d6a5ff\", \"#fca6da\"]\n",
    "fig = tools.make_subplots(rows=1, cols=2, subplot_titles=[\"Visits : GeoNetwork Continent\", \"Visits : GeoNetwork subContinent\"], print_grid=False)\n",
    "trs = []\n",
    "for i,col in enumerate(geo_cols):\n",
    "    t = train[col].value_counts()\n",
    "    tr = go.Bar(x = t.index[:20], marker=dict(color=colors[i]), y = t.values[:20])\n",
    "    trs.append(tr)\n",
    "\n",
    "fig.append_trace(trs[0], 1, 1)\n",
    "fig.append_trace(trs[1], 1, 2)\n",
    "fig['layout'].update(height=400, margin=dict(b=150), showlegend=False)\n",
    "iplot(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "geo_cols = ['geoNetwork_continent','geoNetwork_subContinent']\n",
    "fig = tools.make_subplots(rows=1, cols=2, subplot_titles=[\"Mean Revenue: Continent\", \"Mean Revenue: SubContinent\"], print_grid=False)\n",
    "\n",
    "colors = [\"blue\", \"orange\"]\n",
    "trs = []\n",
    "for i, col in enumerate(geo_cols):\n",
    "    tmp = train.groupby(col).agg({\"totals_transactionRevenue\": \"mean\"}).reset_index().rename(columns={\"totals_transactionRevenue\" : \"Mean Revenue\"})\n",
    "    tmp = tmp.dropna().sort_values(\"Mean Revenue\", ascending = False)\n",
    "    tr = go.Bar(y = tmp[\"Mean Revenue\"], orientation=\"v\", marker=dict(opacity=0.5, color=colors[i]), x= tmp[col])\n",
    "    trs.append(tr)\n",
    "\n",
    "fig.append_trace(trs[0], 1, 1)\n",
    "fig.append_trace(trs[1], 1, 2)\n",
    "fig['layout'].update(height=450, margin=dict(b=200), showlegend=False)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 'geoNetwork' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:55.816091Z",
     "start_time": "2024-05-18T12:18:52.064791Z"
    }
   },
   "outputs": [],
   "source": [
    "geo_columns = ['geoNetwork_continent', 'geoNetwork_subContinent', 'geoNetwork_country', \n",
    "               'geoNetwork_region', 'geoNetwork_metro', 'geoNetwork_city', 'geoNetwork_networkDomain']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "\n",
    "for i, col in enumerate(geo_columns, 1):\n",
    "    plt.subplot(2, 4, i)\n",
    "    \n",
    "    ax = sns.countplot(y=train[col], order=train[col].value_counts()[:10].index,  )\n",
    "    plt.title(f'Count of {col}')    \n",
    "    \n",
    "    total = len(train[col])\n",
    "\n",
    "    for c in ax.containers:\n",
    "        percentages = [f'{(v / total) * 100:.2f}%' for v in c.datavalues]\n",
    "        ax.bar_label(c, labels=percentages, fmt='%s', padding=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Explicitly close the figure to remove overlapping axes\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Global Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:55.927890Z",
     "start_time": "2024-05-18T12:18:55.816091Z"
    }
   },
   "outputs": [],
   "source": [
    "df_country = df_train.groupby('geoNetwork_country').agg(aggregations\n",
    "                    ).sort_values(by=['totals_transactionRevenue'], \n",
    "                                  ascending=False).reset_index()\n",
    "df_country.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:56.105242Z",
     "start_time": "2024-05-18T12:18:55.927890Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create basic choropleth map\n",
    "fig = px.choropleth(df_country, locationmode='country names', locations='geoNetwork_country', \n",
    "                    color=df_country['totals_transactionRevenue'], color_continuous_scale='Mint', \n",
    "                    hover_name='geoNetwork_country',  hover_data={'totals_transactionRevenue':':,.0f'},\n",
    "                    title='Revenue by Country')\n",
    "\n",
    "fig.update_layout(width=800, height=400, autosize=False, \n",
    "                  margin=dict(l=30, r=30, t=50, b=50, pad=10))\n",
    "\n",
    "fig.show(renderer='notebook')\n",
    "# fig.write_html(\"interactive_map.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 US Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:56.308409Z",
     "start_time": "2024-05-18T12:18:56.108491Z"
    }
   },
   "outputs": [],
   "source": [
    "df_us = df_train[df_train['geoNetwork_country'] == 'United States'].reset_index(drop=True)\n",
    "df_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:56.358998Z",
     "start_time": "2024-05-18T12:18:56.308915Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add a column with state abbreviations\n",
    "state_abbreviations = {'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA',\n",
    "                       'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'Florida': 'FL', 'Georgia': 'GA',\n",
    "                       'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA',\n",
    "                       'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD',\n",
    "                       'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS',\n",
    "                       'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH',\n",
    "                       'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC',\n",
    "                       'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK', 'Oregon': 'OR', 'Pennsylvania': 'PA',\n",
    "                       'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD', 'Tennessee': 'TN',\n",
    "                       'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA',\n",
    "                       'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY', 'District of Columbia': 'DC' }\n",
    "\n",
    "df_us['stateCode'] = df_us['geoNetwork_region'].map(state_abbreviations)\n",
    "df_us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:56.461956Z",
     "start_time": "2024-05-18T12:18:56.358998Z"
    }
   },
   "outputs": [],
   "source": [
    "df_states = df_us.groupby(['geoNetwork_region', 'stateCode']).agg(aggregations).sort_values(\n",
    "                                            by='totals_transactionRevenue', ascending=False).reset_index()\n",
    "df_states.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:18:56.577202Z",
     "start_time": "2024-05-18T12:18:56.461956Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create basic choropleth map\n",
    "fig = px.choropleth(df_states, locationmode='USA-states', locations='stateCode',\n",
    "                    color=df_states['totals_transactionRevenue'], hover_name='geoNetwork_region', \n",
    "                    hover_data={'totals_transactionRevenue':':,.0f'}, \n",
    "                    title='Revenue by State', color_continuous_scale='Mint')\n",
    "                  \n",
    "fig.update_layout(width=800, height=400, autosize=False, geo_scope='usa',\n",
    "                  margin=dict(l=30, r=30, t=50, b=50, pad=10))\n",
    "\n",
    "# For interactive display in a Jupyter Notebook:\n",
    "fig.show(renderer='notebook')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 'trafficSource' Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:03.029898Z",
     "start_time": "2024-05-18T12:18:56.577202Z"
    }
   },
   "outputs": [],
   "source": [
    "traffic_columns = ['trafficSource_campaign', 'trafficSource_source', 'trafficSource_medium', \n",
    "                   'trafficSource_keyword', 'trafficSource_referralPath', \n",
    "                   'trafficSource_adwordsClickInfo.page', 'trafficSource_adwordsClickInfo.slot', \n",
    "                   'trafficSource_adwordsClickInfo.adNetworkType', 'trafficSource_adContent']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 12))\n",
    "\n",
    "for i, col in enumerate(traffic_columns, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    \n",
    "    # Exclude 'others' & '(not set)' from the specified column\n",
    "    filtered_df = train[(train[col] != 'others') & \n",
    "                        (train[col] != '(not provided)') & \n",
    "                        (train[col] != '(not set)')]\n",
    "    \n",
    "    ax = sns.countplot(y=filtered_df[col], order=filtered_df[col].value_counts()[:7].index)\n",
    "    plt.title(f'Count of {col}')\n",
    "\n",
    "    total = len(train[col])\n",
    "\n",
    "    for c in ax.containers:\n",
    "        percentages = [f'{(v / total) * 100:.2f}%' for v in c.datavalues]\n",
    "        ax.bar_label(c, labels=percentages, fmt='%s', padding=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Explicitly close the figure to remove overlapping axes\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we have excluded 'others' & '(not set)' from the specified columns for they comprise    \n",
    "an overwhelming large part of the data in this section.\n",
    "\n",
    "We are only interested in the foloowing features:   \n",
    "\n",
    "- 'trafficSource.source'    \n",
    "- 'trafficSource.medium'   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 'trafficSource.source'\n",
    "\n",
    "- The source of the traffic source. Could be the name of the search engine, etc.\n",
    "- Top 10 sources are:   \n",
    "    'google', 'youtube.com', '(direct)', 'mall.googleplex.com', 'Partners',   \n",
    "    'analytics.google.com', 'dfa', 'google.com', 'm.facebook.com', 'baidu'.      \n",
    "    google: 44% of the trafficsource source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:03.153321Z",
     "start_time": "2024-05-18T12:19:03.029898Z"
    }
   },
   "outputs": [],
   "source": [
    "df_source = df_train.groupby('trafficSource_source').agg(aggregations\n",
    "                ).sort_values(by='totals_transactionRevenue', ascending=False).head(10)\n",
    "\n",
    "df_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:03.903887Z",
     "start_time": "2024-05-18T12:19:03.153321Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "\n",
    "# Plot each column in a separate subplot\n",
    "for i, col in enumerate(df_source.columns):\n",
    "    df_source[col].sort_values().plot(kind='barh', ax=axes[i], color=colors)\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel('Count')\n",
    "\n",
    "    total = df_source[col].sum()\n",
    "\n",
    "    for c in axes[i].containers:\n",
    "        percentages = [f'{(v / total) * 100:.2f}%' for v in c.datavalues]\n",
    "        axes[i].bar_label(c, labels=percentages, fmt='%s', padding=1)\n",
    "\n",
    "plt.suptitle('TrafficSource Source')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Observations:**\n",
    "\n",
    "'trafficSource_source'    \n",
    "    \n",
    "- 'google' brings in most of the users & pageviews, while 'mall.googleplex.com' generates most of the revenues.\n",
    "- '(direct)' ranks second in all 3 fields. No wonder again, users know what they want & type the urls in the browser.\n",
    "- 'dfa': DFA source refers to DoubleClick For Advertisers, which is the old brand name for Google Marketing Platform. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 'trafficSource_medium'\n",
    "\n",
    "- The medium of the traffic source. \"organic\", \"cpc\", \"referral\", etc,   \n",
    "- Top 6 sources are:   \n",
    "    'organic', 'referral', '(none)', 'cpc', 'affiliate', 'cpm', etc.   \n",
    "    organic: 42% of the traffucesource medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:04.010862Z",
     "start_time": "2024-05-18T12:19:03.903887Z"
    }
   },
   "outputs": [],
   "source": [
    "df_medium = df_train.groupby('trafficSource_medium').agg(aggregations\n",
    "                ).sort_values(by='totals_transactionRevenue', ascending=False).head(10)\n",
    "\n",
    "df_medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:04.728234Z",
     "start_time": "2024-05-18T12:19:04.012382Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "\n",
    "# Plot each column in a separate subplot\n",
    "for i, col in enumerate(df_medium.columns):\n",
    "    df_medium[col].sort_values().plot(kind='barh', ax=axes[i], color=colors)\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel('Count')\n",
    "\n",
    "    total = df_medium[col].sum()\n",
    "\n",
    "    for c in axes[i].containers:\n",
    "        percentages = [f'{(v / total) * 100:.2f}%' for v in c.datavalues]\n",
    "        axes[i].bar_label(c, labels=percentages, fmt='%s', padding=1)\n",
    "\n",
    "plt.suptitle('TrafficSource Medium')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Observations:**\n",
    "\n",
    "- \"organic\" bring about most of the sessions & pageviews, it is   \n",
    "    \"referral\" that generates most of the revenues. \n",
    "- \"cpc\": Cost Per Click. Plays an important role in all 3 fields.\n",
    "- '(none)': means Analytics doesn't have any referral information for these users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Source & Medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:04.906253Z",
     "start_time": "2024-05-18T12:19:04.728234Z"
    }
   },
   "outputs": [],
   "source": [
    "df_source_medium = df_train.groupby(['trafficSource_source', 'trafficSource_medium']).agg(aggregations)\n",
    "\n",
    "# df_source_medium.sort_values(by='revenue', ascending=False).head(10)\n",
    "df_source_medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:05.758080Z",
     "start_time": "2024-05-18T12:19:04.906253Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "# Flatten the 2D array of axes\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# Plot each column in a separate subplot\n",
    "for i, col in enumerate(df_source_medium.columns):\n",
    "    df_source_medium[col].sort_values(ascending=False)[:10].plot(kind='barh', ax=axes[i], color=colors)\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel('Count')\n",
    "\n",
    "    total = df_source_medium[col].sum()\n",
    "\n",
    "    for c in axes[i].containers:\n",
    "        percentages = [f'{(v / total) * 100:.2f}%' for v in c.datavalues]\n",
    "        axes[i].bar_label(c, labels=percentages, fmt='%s', padding=1)\n",
    "\n",
    "plt.suptitle('TrafficSource Source & Medium')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Observations:**\n",
    "\n",
    "- 'google organic' generates most of the traffics, the rererrals from    \n",
    "    'mall.googleplex.com' generates most of the revenue.\n",
    "- 'direct none': again, Analytics does not have any information about users,   \n",
    "    yet are dominant in all 3 fields on average after 'google organic'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Revenue = 0 vs Revenue > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:05.959836Z",
     "start_time": "2024-05-18T12:19:05.758080Z"
    }
   },
   "outputs": [],
   "source": [
    "# revenue = 0 transactions\n",
    "df_revenue_zero = df_train[df_train['totals_transactionRevenue'] == 0]\n",
    "df_revenue_zero.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:06.005909Z",
     "start_time": "2024-05-18T12:19:05.975454Z"
    }
   },
   "outputs": [],
   "source": [
    "# revenue > 0 transactions\n",
    "df_revenue_nonzero = df_train[df_train['totals_transactionRevenue'] > 0].reset_index(drop=True)\n",
    "df_revenue_nonzero.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:06.013149Z",
     "start_time": "2024-05-18T12:19:06.006925Z"
    }
   },
   "outputs": [],
   "source": [
    "non_zero_transact_pct = len(df_revenue_nonzero) / len(df_train) * 100\n",
    "print(f'Non-Zero Transaction Percentage: {non_zero_transact_pct:.02f}%')\n",
    "\n",
    "zero_transact_pct = len(df_revenue_zero) / len(df_train) * 100\n",
    "print(f'Zero Transaction Percentage: {zero_transact_pct:.02f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">***Observations:***\n",
    "\n",
    "- 98.73% of the traffics (sessions, pageviews) does not generate revenues at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:06.966997Z",
     "start_time": "2024-05-18T12:19:06.013149Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter the DataFrame for zero revenue\n",
    "# df_revenue_zero = df_train[df_train['totals.transactionRevenue'] == 0]\n",
    "\n",
    "# List of columns to loop through\n",
    "columns_to_loop = ['channelGrouping', 'trafficSource_source', 'trafficSource_medium']\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Loop through each column and subplot\n",
    "for i, column in enumerate(columns_to_loop):\n",
    "    # Create the aggregated DataFrame\n",
    "    df_column_revenue_zero = df_revenue_zero.groupby(column).agg(\n",
    "        count=(column, 'count') ).sort_values(by='count', ascending=False).head(10)\n",
    "\n",
    "    # Calculate the percentage\n",
    "    total_count = df_column_revenue_zero['count'].sum()\n",
    "    df_column_revenue_zero['percentage'] = (df_column_revenue_zero['count'] / total_count) * 100\n",
    "\n",
    "    # Plot the horizontal bar chart in the current subplot\n",
    "    bar_chart = df_column_revenue_zero['count'].plot(kind='barh', ax=axs[i], color=colors)\n",
    "\n",
    "    # Add labels and title\n",
    "    axs[i].set_xlabel(f'Count of Zero Transactions ({column})')\n",
    "    axs[i].set_ylabel(column)\n",
    "    axs[i].set_title(f'Top 10 {column} with Zero Transactions')\n",
    "\n",
    "    # Display percentages on the right side of the bars\n",
    "    for j, patch in enumerate(bar_chart.patches):\n",
    "        width = patch.get_width()\n",
    "        percentage = df_column_revenue_zero['percentage'].iloc[j]\n",
    "        axs[i].text(width + 1000, patch.get_y() + patch.get_height() / 2,\n",
    "                    f'{percentage:.2f}%', ha='left', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:07.720404Z",
     "start_time": "2024-05-18T12:19:06.969034Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter the DataFrame for non-zero revenue\n",
    "# df_revenue_nonzero = df_train[df_train['totals_transactionRevenue'] > 0]\n",
    "\n",
    "# List of columns to loop through\n",
    "columns_to_loop = ['channelGrouping', 'trafficSource_source', 'trafficSource_medium']\n",
    "\n",
    "# Plot the bar chart\n",
    "fig, ax = plt.subplots(3, 1, figsize=(10, 9))\n",
    "\n",
    "# Loop through each column\n",
    "for i, col in enumerate(columns_to_loop):\n",
    "    # Create the aggregated DataFrame\n",
    "    df_column_revenue_nonzero = df_revenue_nonzero.groupby(col).agg(\n",
    "        count=(col, 'count')\n",
    "    ).sort_values(by='count', ascending=False).head(10)\n",
    "\n",
    "    # Calculate the percentage\n",
    "    total_count = df_column_revenue_nonzero['count'].sum()\n",
    "    df_column_revenue_nonzero['percentage'] = (df_column_revenue_nonzero['count'] / total_count) * 100\n",
    "\n",
    "    bar_chart = df_column_revenue_nonzero['count'].plot(kind='bar', rot=0, ax=ax[i], color=colors)\n",
    "\n",
    "    # Add labels and title\n",
    "    ax[i].set_ylabel(f'Count of Non-Zero Transactions ({col})')\n",
    "    ax[i].set_xlabel(col)\n",
    "    ax[i].set_title(f'Top 10 {col} with Non-Zero Transactions')\n",
    "\n",
    "    # Display percentages on top of the bars\n",
    "    for j, patch in enumerate(bar_chart.patches):\n",
    "        height = patch.get_height()\n",
    "        percentage = df_column_revenue_nonzero['percentage'].iloc[j]\n",
    "        ax[i].text(patch.get_x() + patch.get_width() / 2,\n",
    "                height + 1000, f'{percentage:.2f}%', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:08.936558Z",
     "start_time": "2024-05-18T12:19:07.720404Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter the DataFrame for zero revenue\n",
    "# df_revenue_zero = df_train[df_train['totals_transactionRevenue'] == 0]\n",
    "\n",
    "# List of columns to loop through\n",
    "columns_to_loop = ['channelGrouping', 'trafficSource_source', 'trafficSource_medium']\n",
    "\n",
    "# Loop through each column\n",
    "for col in columns_to_loop:\n",
    "    # Create the aggregated DataFrame\n",
    "    df_column_revenue_zero = df_revenue_zero.groupby(col).agg(\n",
    "        count=(col, 'count')\n",
    "    ).sort_values(by='count', ascending=False).head(10)\n",
    "\n",
    "    # Calculate the percentage\n",
    "    total_count = df_column_revenue_zero['count'].sum()\n",
    "    df_column_revenue_zero['percentage'] = (df_column_revenue_zero['count'] / total_count) * 100\n",
    "\n",
    "    # Plot the bar chart\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    # Flatten the 2D array of axes\n",
    "    # axes = axes.flatten()\n",
    "\n",
    "    bar_chart = df_column_revenue_zero['count'].plot(kind='bar', rot=0, ax=ax, color=colors)\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_ylabel(f'Count of Zero Transactions ({col})')\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_title(f'Top 10 {col} with Zero Transactions')\n",
    "\n",
    "    # Display percentages on top of the bars\n",
    "    for i, patch in enumerate(bar_chart.patches):\n",
    "        height = patch.get_height()\n",
    "        percentage = df_column_revenue_zero['percentage'].iloc[i]\n",
    "        ax.text(patch.get_x() + patch.get_width() / 2,\n",
    "                height + 1000, f'{percentage:.2f}%', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Observations:**\n",
    "\n",
    "- Most of the zero-revenue transacations are from 'organic search' or 'search google'\n",
    "- while most of the non-zero transactions are from 'mall.googleplex.com' & 'referral',    \n",
    "    '(direct)' plays an important role in bringing about traffics & revenues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. User & Session Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 User Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:10.803294Z",
     "start_time": "2024-05-18T12:19:08.936558Z"
    }
   },
   "outputs": [],
   "source": [
    "df_visitors = df_train.groupby('fullVisitorId').agg(aggregations).sort_values(\n",
    "                    by='totals_transactionRevenue', ascending=False )\n",
    "\n",
    "df_visitors.drop('fullVisitorId', axis=1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:10.850591Z",
     "start_time": "2024-05-18T12:19:10.803815Z"
    }
   },
   "outputs": [],
   "source": [
    "# Users with non-zero revenue transactions\n",
    "df_users_revenue = df_revenue_nonzero.groupby('fullVisitorId').agg(aggregations\n",
    "                ).sort_values(by='totals_transactionRevenue', ascending=False)\n",
    "\n",
    "df_users_revenue.drop('fullVisitorId', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:11.923817Z",
     "start_time": "2024-05-18T12:19:10.850591Z"
    }
   },
   "outputs": [],
   "source": [
    "# Distribution of non-zero revenue transactions\n",
    "non_zero = df_train[df_train['totals_transactionRevenue'] > 0] \\\n",
    "                 ['totals_transactionRevenue'].reset_index(drop=True)\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "sns.histplot(non_zero, kde=True, bins=30, log_scale=True)\n",
    "ticks_x = ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000))\n",
    "ax.xaxis.set_major_formatter(ticks_x)\n",
    "\n",
    "plt.title('Distribution of Non-Zero Revenue Transactions')\n",
    "plt.xlabel('Transaction Revenue in Thousands')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:13.702370Z",
     "start_time": "2024-05-18T12:19:11.930773Z"
    }
   },
   "outputs": [],
   "source": [
    "# Users with zero revenue transactions\n",
    "df_user_revenue_zero = df_revenue_zero.groupby('fullVisitorId').agg(aggregations\n",
    "                ).sort_values(by='totals_transactionRevenue', ascending=False)\n",
    "\n",
    "df_user_revenue_zero.drop('fullVisitorId', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:13.712331Z",
     "start_time": "2024-05-18T12:19:13.702370Z"
    }
   },
   "outputs": [],
   "source": [
    "df_user_revenue_zero_pct = round(len(df_user_revenue_zero['totals_transactionRevenue']) / \n",
    "                                 len(df_train['totals_transactionRevenue']) * 100, 2)\n",
    "print(f'Percentage of users witn zero-revenue trasactions:\\n {df_user_revenue_zero_pct}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:13.751508Z",
     "start_time": "2024-05-18T12:19:13.714328Z"
    }
   },
   "outputs": [],
   "source": [
    "# Non-zero revenue sessions\n",
    "df_session_revenue = df_revenue_nonzero.groupby('sessionId').agg(\n",
    "                count=('sessionId', 'count'),\n",
    "                pageviews=('totals_pageviews', 'sum'),\n",
    "                revenue=('totals_transactionRevenue', 'sum')\n",
    "                ).sort_values(by='revenue', ascending=False)\n",
    "\n",
    "df_session_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:15.979821Z",
     "start_time": "2024-05-18T12:19:13.751508Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sessions with zero revenue transactions\n",
    "df_session_revenue_zero = df_revenue_zero.groupby('sessionId').agg(\n",
    "                sessions=('sessionId', 'count'),\n",
    "                pageviews=('totals_pageviews', 'sum'),\n",
    "                revenue=('totals_transactionRevenue', 'sum')\n",
    "                ).sort_values(by='revenue', ascending=False)\n",
    "\n",
    "df_session_revenue_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:15.991799Z",
     "start_time": "2024-05-18T12:19:15.980846Z"
    }
   },
   "outputs": [],
   "source": [
    "df_session_revenue_zero_pct = round(len(df_session_revenue_zero['revenue']) / \n",
    "                                    len(df_train['totals_transactionRevenue']) * 100, 2)\n",
    "\n",
    "print(f'Percentage of sessions witn zero-revenue trasactions:\\n {df_session_revenue_zero_pct}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Time Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Extract 'Year', 'Month', 'Month_Num' & 'Day' from 'date' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:16.005188Z",
     "start_time": "2024-05-18T12:19:15.993948Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract 'Year', 'Month', 'Month_Num' & 'Day' from 'date'\n",
    "def create_features(data):\n",
    "    \"\"\"\n",
    "    Create time series features based on time series index.\n",
    "    \"\"\"\n",
    "\n",
    "    # data = data.copy()\n",
    "    \n",
    "    # Convert 'date' column to datetime series \n",
    "    data['date'] = pd.to_datetime(data['date'], format='%Y%m%d')\n",
    "\n",
    "    # Extract 'Year', 'Month', 'Month_Num' & 'Day' from 'Order Date'\n",
    "    data['Year'] = data.date.dt.year\n",
    "    data['Month'] = data.date.dt.strftime('%b') # abbrev month name\n",
    "    data['Month_Num'] = data.date.dt.month\n",
    "    data['Day'] = data.date.dt.day\n",
    "\n",
    "    # Extract 'Weekday' & 'Week Day Num'\n",
    "    data['Weekday'] = data['date'].dt.strftime('%a')\n",
    "    data['Weekday_Num'] = data.date.dt.day_of_week + 1 # Week start on Monday as 0, so + 1\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:25.431789Z",
     "start_time": "2024-05-18T12:19:16.005188Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_train.copy()\n",
    "\n",
    "create_features(df_train)\n",
    "\n",
    "df_train = df_train[df_train['date'] != '2017-08-01']\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Daily Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:25.436922Z",
     "start_time": "2024-05-18T12:19:25.431789Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:25.491064Z",
     "start_time": "2024-05-18T12:19:25.436922Z"
    }
   },
   "outputs": [],
   "source": [
    "df_daily = df_train.groupby('date').agg(aggregations)\n",
    "df_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:26.337319Z",
     "start_time": "2024-05-18T12:19:25.491064Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(15, 6), sharex=True)\n",
    "\n",
    "ticks_y = ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000000))\n",
    "\n",
    "sns.lineplot(data=df_daily, x='date', y='totals_transactionRevenue', color='g', label='Revenue in Millions', ax=ax[0])\n",
    "# plt.gca(ax=ax[0]).yaxis.set_major_formatter(ticks_y)\n",
    "ax[0].yaxis.set_major_formatter(ticks_y)\n",
    "\n",
    "# sns.lineplot(data=df_daily, x='date', y='totals.hits', color='b', label='Hits', ax=ax[1])\n",
    "sns.lineplot(data=df_daily, x='date', y='totals_pageviews', color='b', label='Pageviews', ax=ax[1])\n",
    "\n",
    "sns.lineplot(data=df_daily, x='date', y='fullVisitorId', color='k', label='Visitors', ax=ax[2])\n",
    "\n",
    "plt.legend()\n",
    "plt.suptitle('Daily Visitors, Pageviews & Revenue')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Weekly Anslysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:26.497587Z",
     "start_time": "2024-05-18T12:19:26.339038Z"
    }
   },
   "outputs": [],
   "source": [
    "df_week = df_train.groupby(['Weekday', 'Weekday_Num']).agg(aggregations)\n",
    "\n",
    "df_week.sort_values(by='Weekday_Num', inplace=True)\n",
    "df_week "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:19:27.265004Z",
     "start_time": "2024-05-18T12:19:26.497587Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 4), sharex=False)\n",
    "\n",
    "sns.lineplot(data=df_week, x='Weekday', y='fullVisitorId', color='k', label='Visitors', ax=ax[0])\n",
    "sns.lineplot(data=df_week, x='Weekday', y='totals_pageviews', color='b', label='Pageviews', ax=ax[1])\n",
    "\n",
    "ticks_y = ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000000))\n",
    "sns.lineplot(data=df_week, x='Weekday', y='totals_transactionRevenue', color='g', label='Revenuev in Millions', ax=ax[2])\n",
    "ax[2].yaxis.set_major_formatter(ticks_y)\n",
    "\n",
    "plt.legend()\n",
    "plt.suptitle('Weekly Visitors, Pageview & Revenue')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 Monthly Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:20:02.654799Z",
     "start_time": "2024-05-18T12:19:27.265004Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_dates = df_train.set_index(df_train['date']).drop('date', axis=1)\n",
    "\n",
    "# months = df_train_dates['Month'].unique()\n",
    "months = ['Aug', 'Sep', 'Oct', 'Nov', 'Dec', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul']\n",
    "\n",
    "# Set up subplots\n",
    "fig, axes = plt.subplots(nrows=len(months), ncols=1, \n",
    "                         figsize=(10, 3*len(months)))\n",
    "\n",
    "# fig.suptitle('Monthly Revenues in Millions')\n",
    "\n",
    "# Plot for each year\n",
    "for i, month in enumerate(months):\n",
    "    df_monthly = df_train_dates[df_train_dates['Month'] == month]\n",
    "    df_monthly_rev = df_monthly['totals_transactionRevenue']\n",
    "\n",
    "    # Set subplot title\n",
    "    axes[i].set_title(f'Monthly Revenues in Millions - {month}')\n",
    "\n",
    "    ticks_y = ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000000))\n",
    "\n",
    "    # Plot on the i-th subplot\n",
    "    # df_month_rev.plot(kind='line', ax=axes[i], rot=0)\n",
    "    sns.lineplot(data=df_monthly_rev, ax=axes[i], legend=True)\n",
    "    axes[i].yaxis.set_major_formatter(ticks_y)\n",
    "\n",
    "    # Set y-axis scale\n",
    "    # axes[i].set_yscale('log') \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:20:02.921296Z",
     "start_time": "2024-05-18T12:20:02.656954Z"
    }
   },
   "outputs": [],
   "source": [
    "df_month = df_train.groupby(['Year', 'Month', 'Month_Num']).agg(aggregations)\n",
    "df_month = df_month[df_month.index != '2017-08-01']\n",
    "\n",
    "df_month.sort_values(by=['Year', 'Month_Num'], inplace=True)\n",
    "df_month = df_month.reset_index()\n",
    "\n",
    "df_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:20:05.381849Z",
     "start_time": "2024-05-18T12:20:02.923583Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb \n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:20:23.161324Z",
     "start_time": "2024-05-18T12:20:05.382970Z"
    }
   },
   "outputs": [],
   "source": [
    "### Create calendar columns in test dataset\n",
    "df_test = df_test.copy()\n",
    "\n",
    "create_features(df_test)\n",
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:20:24.217100Z",
     "start_time": "2024-05-18T12:20:23.165129Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = df_train.drop(columns=['Year', 'Month', 'Weekday'], axis=1).reset_index(drop=True)\n",
    "test_set = df_test.drop(columns=['Year', 'Month', 'Weekday'], axis=1).reset_index(drop=True)\n",
    "\n",
    "print(train_set.shape, test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:20:24.301666Z",
     "start_time": "2024-05-18T12:20:24.231715Z"
    }
   },
   "outputs": [],
   "source": [
    "# numeric_columns = train_set.select_dtypes(include='number').columns\n",
    "numeric_cols = [c for c in train_set.columns if c.startswith('total') and c != 'totals_transactionRevenue']\n",
    "numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:20:24.631381Z",
     "start_time": "2024-05-18T12:20:24.309059Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in numeric_cols:\n",
    "\n",
    "    # Check for and handle missing values\n",
    "    train_set[col].fillna(0, inplace=True) \n",
    "    test_set[col].fillna(0, inplace=True)\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    # Fit the StandardScaler on the combined data (train and test)\n",
    "    sc.fit(pd.concat([train_set[[col]], test_set[[col]]], axis=0, ignore_index=True))\n",
    "\n",
    "    # Transform the values in both train and test sets\n",
    "    train_set[col] = sc.transform(train_set[[col]])\n",
    "    test_set[col] = sc.transform(test_set[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:20:24.649339Z",
     "start_time": "2024-05-18T12:20:24.632896Z"
    }
   },
   "outputs": [],
   "source": [
    "# categorical_columns = train_set.select_dtypes(include='object').columns\n",
    "\n",
    "## exclude columns for normalization or label-encoding\n",
    "cols_excluded = ['date', 'visitNumber']\n",
    "\n",
    "categorical_cols = [c for c in train_set.columns if c not in cols_excluded and not c.startswith('total')]\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:20:24.772414Z",
     "start_time": "2024-05-18T12:20:24.653512Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert date to UNIX timestamp\n",
    "train_set['date'] = train['date'].astype(int)\n",
    "test_set['date'] = test['date'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:20:54.838595Z",
     "start_time": "2024-05-18T12:20:24.777923Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    # Fit the LabelEncoder on the combined data (train and test)\n",
    "    le.fit(pd.concat([train_set[col], test_set[col]], axis=0, ignore_index=True))\n",
    "    \n",
    "    # Transform the values in both train and test sets\n",
    "    train_set[col] = le.transform(train_set[col])\n",
    "    test_set[col] = le.transform(test_set[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:20:55.392495Z",
     "start_time": "2024-05-18T12:20:54.839537Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train_set.drop('totals_transactionRevenue', axis=1)\n",
    "y = train_set['totals_transactionRevenue']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:21:28.383463Z",
     "start_time": "2024-05-18T12:20:55.394642Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {'num_leaves': 38,              \n",
    "          'min_data_in_leaf': 50,\n",
    "          'objective': 'regression',     \n",
    "          'max_depth': -1,                \n",
    "          'learning_rate': 0.1,           \n",
    "          'verbose': -1,\n",
    "          'predict_disable_shape_check': [True]\n",
    "          }\n",
    "\n",
    "train_data = lgb.Dataset(X_train, y_train)\n",
    "test_data = lgb.Dataset(X_test, y_test)\n",
    "\n",
    "model = lgb.train(params,\n",
    "                train_data,\n",
    "                20000,\n",
    "                valid_sets=[train_data, test_data],\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=500), lgb.log_evaluation(50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:21:28.833326Z",
     "start_time": "2024-05-18T12:21:28.383463Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = model.predict(test_set, num_iteration=model.best_iteration)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:21:29.529806Z",
     "start_time": "2024-05-18T12:21:28.838479Z"
    }
   },
   "outputs": [],
   "source": [
    "test_set[\"PredictedRevenue\"] = preds\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:21:54.327108Z",
     "start_time": "2024-05-18T12:21:29.532853Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_params = {'objective': 'regression',\n",
    "              'metric': 'rmse',\n",
    "              'num_leaves': 50,\n",
    "              'learning_rate': 0.01,\n",
    "              'bagging_fraction': 0.75,\n",
    "              'feature_fraction': 0.8,\n",
    "              'bagging_frequency': 5,\n",
    "              'force_row_wise': True,  \n",
    "              'verbose': -1,\n",
    "              'predict_disable_shape_check': True  \n",
    "}\n",
    "    \n",
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_val = lgb.Dataset(X_test, label=y_test)\n",
    "model_1 = lgb.train(lgb_params, lgb_train, \n",
    "                  num_boost_round=700, \n",
    "                  valid_sets=[lgb_val], \n",
    "                  callbacks=[lgb.early_stopping(stopping_rounds=500), \n",
    "                             lgb.log_evaluation(50), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:21:54.576499Z",
     "start_time": "2024-05-18T12:21:54.327108Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_1 = model_1.predict(test_set.loc[:, test_set.columns != 'PredictedRevenue'], \n",
    "                          num_iteration=model.best_iteration, )\n",
    "preds_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:21:54.888714Z",
     "start_time": "2024-05-18T12:21:54.576499Z"
    }
   },
   "outputs": [],
   "source": [
    "test_set[\"PredictedRevenue\"] = preds_1\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:21:54.894940Z",
     "start_time": "2024-05-18T12:21:54.888714Z"
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:22:04.517951Z",
     "start_time": "2024-05-18T12:21:54.894940Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_params = {'num_leaves' : 50, 'learning_rate' : 0.01, \n",
    "              'bagging_fraction' : 0.75, 'feature_fraction' : 0.8, \n",
    "              'bagging_frequency' : 5, 'force_row_wise': [True], \n",
    "              'verbose': -1,}\n",
    "    \n",
    "model_2 = LGBMRegressor(**lgb_params, n_estimators=700)\n",
    "model_2.fit(X_train, y_train, \n",
    "          eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:22:04.827914Z",
     "start_time": "2024-05-18T12:22:04.517951Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_2 = model_2.predict(test_set.loc[:, test_set.columns != 'PredictedRevenue'], \n",
    "                          num_iteration=model.best_iteration, )\n",
    "preds_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:22:05.172555Z",
     "start_time": "2024-05-18T12:22:04.829988Z"
    }
   },
   "outputs": [],
   "source": [
    "test_set[\"PredictedRevenue\"] = preds_2\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:22:12.013127Z",
     "start_time": "2024-05-18T12:22:05.172555Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install Flask pandas xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:22:12.035224Z",
     "start_time": "2024-05-18T12:22:12.013127Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "# Assuming `model` is your trained XGBoost model\n",
    "joblib.dump(model, 'xgboost_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:22:12.040879Z",
     "start_time": "2024-05-18T12:22:12.035224Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:22:12.046512Z",
     "start_time": "2024-05-18T12:22:12.040879Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 180088,
     "sourceId": 10038,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
